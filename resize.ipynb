{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6138b6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] class='Mild Impairment' src_count=2560 chosen=2000 -> saving to c:\\Users\\saike\\Downloads\\medimg_py397\\final_final_resized\\Mild Impairment\n",
      "[INFO] class='Moderate Impairment' src_count=2560 chosen=2000 -> saving to c:\\Users\\saike\\Downloads\\medimg_py397\\final_final_resized\\Moderate Impairment\n",
      "[INFO] class='No Impairment' src_count=2560 chosen=2000 -> saving to c:\\Users\\saike\\Downloads\\medimg_py397\\final_final_resized\\No Impairment\n",
      "[INFO] class='Very Mild Impairment' src_count=2560 chosen=2000 -> saving to c:\\Users\\saike\\Downloads\\medimg_py397\\final_final_resized\\Very Mild Impairment\n",
      "Done. Reduced dataset saved to: c:\\Users\\saike\\Downloads\\medimg_py397\\final_final_resized\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "SRC_DIR = r\"c:\\Users\\saike\\Downloads\\medimg_py397\\final_final\"\n",
    "OUT_DIR = r\"c:\\Users\\saike\\Downloads\\medimg_py397\\final_final_resized\"\n",
    "IMG_SIZE = (128, 128)        # width, height\n",
    "TARGET_PER_CLASS = 2000\n",
    "RANDOM_SEED = 42\n",
    "VALID_EXT = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "def is_image_file(name):\n",
    "    return os.path.splitext(name.lower())[1] in VALID_EXT\n",
    "\n",
    "for cls in sorted(os.listdir(SRC_DIR)):\n",
    "    src_cls = os.path.join(SRC_DIR, cls)\n",
    "    if not os.path.isdir(src_cls):\n",
    "        continue\n",
    "    out_cls = os.path.join(OUT_DIR, cls)\n",
    "    os.makedirs(out_cls, exist_ok=True)\n",
    "\n",
    "    # collect image files\n",
    "    files = [f for f in os.listdir(src_cls) if is_image_file(f) and os.path.isfile(os.path.join(src_cls, f))]\n",
    "    if len(files) == 0:\n",
    "        print(f\"[WARN] no images found in {src_cls}, skipping\")\n",
    "        continue\n",
    "\n",
    "    # sample files\n",
    "    if len(files) < TARGET_PER_CLASS:\n",
    "        print(f\"[WARN] class '{cls}' has only {len(files)} images (< {TARGET_PER_CLASS}). All will be used.\")\n",
    "        chosen = sorted(files)\n",
    "    else:\n",
    "        random.shuffle(files)\n",
    "        chosen = files[:TARGET_PER_CLASS]\n",
    "\n",
    "    print(f\"[INFO] class='{cls}' src_count={len(files)} chosen={len(chosen)} -> saving to {out_cls}\")\n",
    "\n",
    "    # process and write\n",
    "    for i, fname in enumerate(sorted(chosen)):\n",
    "        src_path = os.path.join(src_cls, fname)\n",
    "        img = cv2.imread(src_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"  [SKIP] cannot read: {src_path}\")\n",
    "            continue\n",
    "        resized = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "        # create a safe unique name to avoid collisions\n",
    "        out_name = f\"{i:05d}_{fname}\"\n",
    "        out_path = os.path.join(out_cls, out_name)\n",
    "        cv2.imwrite(out_path, resized)\n",
    "\n",
    "print(\"Done. Reduced dataset saved to:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e58415b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original images: 488\n",
      "ðŸŽ‰ DONE! Moderate Dementia class balanced.\n",
      "Final image count: 2928\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# --------------------------------\n",
    "# 1. PATHS\n",
    "# --------------------------------\n",
    "SOURCE_DIR = r\"C:\\Users\\saike\\Downloads\\medimg_py397\\OASIS Dataset\\input\\Moderate Dementia\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\saike\\Downloads\\medimg_py397\\balanced_dataset\\Moderate Dementia\"\n",
    "TARGET_COUNT = 3000\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --------------------------------\n",
    "# 2. AUGMENTATION CONFIG\n",
    "# --------------------------------\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.8, 1.2),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# --------------------------------\n",
    "# 3. LOAD IMAGES\n",
    "# --------------------------------\n",
    "images = [f for f in os.listdir(SOURCE_DIR)\n",
    "          if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "print(\"Original images:\", len(images))\n",
    "\n",
    "# Copy originals\n",
    "for img_name in images:\n",
    "    shutil.copy(\n",
    "        os.path.join(SOURCE_DIR, img_name),\n",
    "        os.path.join(OUTPUT_DIR, img_name)\n",
    "    )\n",
    "\n",
    "# --------------------------------\n",
    "# 4. AUGMENT SAFELY (NO save_to_dir)\n",
    "# --------------------------------\n",
    "needed = TARGET_COUNT - len(images)\n",
    "aug_index = 0\n",
    "\n",
    "for img_name in images:\n",
    "    if needed <= 0:\n",
    "        break\n",
    "\n",
    "    img_path = os.path.join(SOURCE_DIR, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    aug_iter = datagen.flow(img, batch_size=1)\n",
    "\n",
    "    for _ in range(5):\n",
    "        if needed <= 0:\n",
    "            break\n",
    "\n",
    "        augmented = next(aug_iter)[0]   # get augmented image\n",
    "        augmented = augmented.astype(np.uint8)\n",
    "\n",
    "        save_name = f\"aug_{aug_index}.jpg\"\n",
    "        save_path = os.path.join(OUTPUT_DIR, save_name)\n",
    "\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        aug_index += 1\n",
    "        needed -= 1\n",
    "\n",
    "print(\"ðŸŽ‰ DONE! Moderate Dementia class balanced.\")\n",
    "print(\"Final image count:\", len(os.listdir(OUTPUT_DIR)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79fb8d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] class='Mild Dementia' src_count=3000 chosen=2000 -> saving to c:\\Users\\saike\\Downloads\\medimg_py397\\OASIS Dataset Resized\\Mild Dementia\n",
      "[INFO] class='Moderate Dementia' src_count=2928 chosen=2000 -> saving to c:\\Users\\saike\\Downloads\\medimg_py397\\OASIS Dataset Resized\\Moderate Dementia\n",
      "[INFO] class='Non Demented' src_count=3000 chosen=2000 -> saving to c:\\Users\\saike\\Downloads\\medimg_py397\\OASIS Dataset Resized\\Non Demented\n",
      "[INFO] class='Very mild Dementia' src_count=3000 chosen=2000 -> saving to c:\\Users\\saike\\Downloads\\medimg_py397\\OASIS Dataset Resized\\Very mild Dementia\n",
      "Done. Reduced dataset saved to: c:\\Users\\saike\\Downloads\\medimg_py397\\OASIS Dataset Resized\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "SRC_DIR = r\"C:\\Users\\saike\\Downloads\\medimg_py397\\OASIS Dataset\\input\"\n",
    "OUT_DIR = r\"c:\\Users\\saike\\Downloads\\medimg_py397\\OASIS Dataset Resized\"\n",
    "IMG_SIZE = (128, 128)        # width, height\n",
    "TARGET_PER_CLASS = 2000\n",
    "RANDOM_SEED = 42\n",
    "VALID_EXT = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "def is_image_file(name):\n",
    "    return os.path.splitext(name.lower())[1] in VALID_EXT\n",
    "\n",
    "for cls in sorted(os.listdir(SRC_DIR)):\n",
    "    src_cls = os.path.join(SRC_DIR, cls)\n",
    "    if not os.path.isdir(src_cls):\n",
    "        continue\n",
    "    out_cls = os.path.join(OUT_DIR, cls)\n",
    "    os.makedirs(out_cls, exist_ok=True)\n",
    "\n",
    "    # collect image files\n",
    "    files = [f for f in os.listdir(src_cls) if is_image_file(f) and os.path.isfile(os.path.join(src_cls, f))]\n",
    "    if len(files) == 0:\n",
    "        print(f\"[WARN] no images found in {src_cls}, skipping\")\n",
    "        continue\n",
    "\n",
    "    # sample files\n",
    "    if len(files) < TARGET_PER_CLASS:\n",
    "        print(f\"[WARN] class '{cls}' has only {len(files)} images (< {TARGET_PER_CLASS}). All will be used.\")\n",
    "        chosen = sorted(files)\n",
    "    else:\n",
    "        random.shuffle(files)\n",
    "        chosen = files[:TARGET_PER_CLASS]\n",
    "\n",
    "    print(f\"[INFO] class='{cls}' src_count={len(files)} chosen={len(chosen)} -> saving to {out_cls}\")\n",
    "\n",
    "    # process and write\n",
    "    for i, fname in enumerate(sorted(chosen)):\n",
    "        src_path = os.path.join(src_cls, fname)\n",
    "        img = cv2.imread(src_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"  [SKIP] cannot read: {src_path}\")\n",
    "            continue\n",
    "        resized = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "        # create a safe unique name to avoid collisions\n",
    "        out_name = f\"{i:05d}_{fname}\"\n",
    "        out_path = os.path.join(out_cls, out_name)\n",
    "        cv2.imwrite(out_path, resized)\n",
    "\n",
    "print(\"Done. Reduced dataset saved to:\", OUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medimg_py397",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
